\chapter{Anhang}

\section{Source Code der angepassten \textit{scatter}-Funktion}

%%
%% Julia definition (c) 2014 Jubobs
%%
\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
      end,export,false,for,function,immutable,import,importall,if,in,%
      macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
      using,while},%
   sensitive=true,%
   alsoother={\$},%
   morecomment=[l]#,%
   morecomment=[n]{#=}{=#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]%

\lstset{%
    language         = Julia,
    basicstyle       = \ttfamily,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{magenta},
    commentstyle     = \color{ForestGreen},
    showstringspaces = false,
}

\label{code_subfig}
\lstset{language=Julia,style=nonumbers}
\begin{lstlisting}[language=Julia]
using CUDA
using ForwardDiff
using NNlibCUDA
using NNlib

_view(X, colons, k) = view(X, colons..., k...)
_view(X, colons, k::Union{Integer, CartesianIndex}) = 
    view(X, colons..., k)
 
maximum_dims(dims::AbstractArray{<:Integer}) = 
    (CUDA.findmax(dims)[1], )
maximum_dims(dims::AbstractArray{NTuple{N, T}}) where {N,T} = 
    ntuple(i -> CUDA.findmax(x->x[i], dims)[1], N)
maximum_dims(dims::AbstractArray{CartesianIndex{N}}) where {N} = 
    ntuple(i -> CUDA.findmax(x->x[i], dims)[1], N)
 
scatter_empty(op, T) = Base.reduce_empty(op, T)
scatter_empty(op::typeof(-), T) = zero(T)
scatter_empty(op::typeof(/), T) = one(T)
scatter_empty(op::typeof(min), T) = typemax(T)
scatter_empty(op::typeof(max), T) = typemin(T)


function NNlib.scatter(op::OP, src::AnyCuArray{Tsrc , Nsrc}, 
                       idx::AnyCuArray{Tidx, Nidx}; 
                       init = nothing, dstsize = nothing) 
                       where {Tsrc <: ForwardDiff.Dual{T, V, N},
                       Tidx,Nsrc,Nidx,OP} where {T, V, N}
    dims = Nsrc - Nidx 
    dstsz = isnothing(dstsize) ? 
            (size(src)[1:dims]..., 
            maximum_dims(idx)...) : dstsize 
    dst = similar(src, Tsrc, dstsz) 
    xinit = isnothing(init) ? scatter_empty(op, Tsrc) : init  
    fill!(dst, xinit) 
    
    return my_scatter(op, dst, src, idx)        
end

function my_scatter(op::OP, dst::AnyCuArray{Tdst, Ndst}, 
                            src::AnyCuArray{Tsrc, Nsrc} , 
                            idx::AnyCuArray{Tidx, Nidx}) 
                            where {Tsrc <: 
                            ForwardDiff.Dual{T, V, N}
                            ,Nsrc,Tidx,Nidx, Tdst, Ndst, OP} 
                            where {T, V, N}   


    dst_i = CuArray{V}(undef, (size(dst)..., N+1)) 
    src_i = CuArray{V}(undef, (size(src)..., N+1))
    
    # Create a tuple similar to Tidx but with one more element 
    if Tidx <: Tuple
        t = typeof(ntuple(x -> one(Tidx.parameters[1]), 
                              length(t.parameters)+1))
    else
        t = typeof(ntuple(x -> one(Tidx), 2))
    end

    # Allocate Space for the larger idx array
    # that is need for scatter!
    idx_i = CuArray{t}(undef, (size(idx)..., N+1))
    copy_dual_to_matrix(dst_i, dst)
    copy_dual_to_matrix(src_i, src)
    modify_index(idx_i, idx)

    NNlib.scatter!(op, dst_i, src_i, idx_i) 
    
    # Create an array that contains tuples 
    # for the partials of a Dual Number
    function f(x...)
        return x
    end
    tuples = f.([view(dst_i, 
             repeat([:], ndims(dst_i)-1)..., i) 
             for i in 2:(N+1)]...)


    # Copy the Result of the Computation 
    # into the destination array
    modify_dual(dst , view(dst_i, repeat([:], 
                ndims(dst_i)-1)..., 1), tuples)
    return dst
end

function copy_dual_to_matrix(dst_i, dst)
    kernel = CUDA.@cuda launch=false 
        copy_dual_to_matrix_kernel(dst_i, dst)
    config = CUDA.launch_configuration(kernel.fun; 
                                max_threads=256)
    threads = min(config.threads, length(dst_i))
    blocks = cld(length(dst_i), threads)
    
    kernel(dst_i, dst; threads=threads, blocks=blocks)
end

function copy_dual_to_matrix_kernel(src::CuDeviceArray{V}, 
            dst::CuDeviceArray{<: ForwardDiff.Dual{T, V, N}}) 
            where {T, V, N}
    index = threadIdx().x + (blockIdx().x - 1) * blockDim().x
   
    if index <= length(src) 
        # Convert the Linear Index index into Koordinates in src
        ci = CartesianIndices(src)
        loc = Tuple(ci[index])
        
        # Copy all values of a dual number 
        # into there respectiv location
        if loc[end] == 1
            src[loc...] = dst[loc[1:end-1]...].value 
        else 
            src[loc...] = 
                dst[loc[1:end-1]...].partials[loc[end]-1]
        end
    end
    return nothing
end

function modify_index(src, dst)
    kernel = CUDA.@cuda launch=false 
                modify_index_kernel(src, dst) 
    config = CUDA.launch_configuration(kernel.fun; 
                                max_threads=256)
    threads = min(length(src), config.threads)
    blocks = cld(length(src), threads)
    
    kernel(src, dst; threads=threads, blocks=blocks)
end

function modify_index_kernel(src::CuDeviceArray, 
                             dst::CuDeviceArray)
    index = threadIdx().x + (blockIdx().x - 1) * blockDim().x
    
    if index <= length(src)
        ci = CartesianIndices(src)
        loc = Tuple(ci[index])
        src[loc...] =  (dst[loc[1:end-1]...]..., loc[end])
    end
    return nothing
end

function modify_dual(dst, v, src)
    kernel = CUDA.@cuda launch=false dual_kernel(dst, v, src)
    config = CUDA.launch_configuration(kernel.fun; 
                                    max_threads=256)
    threads = min(length(dst), config.threads)
    blocks = cld(length(dst), threads)
    
    kernel(dst, v, src; threads=threads, blocks=blocks)
end

function dual_kernel(dst::CuDeviceArray{<: 
                ForwardDiff.Dual{T, V, N}}, 
                v::CuDeviceArray{V}, 
                src::CuDeviceArray{NTuple{N, V}}) 
                where {T, V, N}
    index = threadIdx().x + (blockIdx().x - 1) * blockDim().x
   
    if index <= length(src)
        ci = CartesianIndices(dst)
        loc = Tuple(ci[index])
        dst[loc...]= ForwardDiff.Dual{T, V, N}(v[loc...], 
                     ForwardDiff.Partials{N, V}(src[loc...]))
    end
    return nothing
end
\end{lstlisting}

\newpage

\section{Tabllen der Funktionierenden Impliziten Lösungs Algorithmen}
\label{solver_tabels}

\begin{table}[H]
    \centering
    
    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name             & Funktionale & Fehler \\
        \hline\hline        
        ImplicitEuler    & true        & \\ 
        ImplicitMidpoint & true        & \\ 
        Trapezoid        & true        & \\ 
        TRBDF2           & true        & \\ 
        SDIRK2           & true        & \\ 
        Kvaerno3         & true        & \\ 
        KenCarp3         & true        & \\ 
        Cash4            & true        & \\ 
        Hairer4          & true        & \\ 
        Hairer42         & true        & \\ 
        Kvaerno4         & true        & \\ 
        KenCarp4         & true        & \\ 
        KenCarp47        & true        & \\ 
        Kvaerno5         & true        & \\ 
        KenCarp5         & true        & \\ 
        KenCarp58        & true        & \\       
    \end{tabular}
    \caption{SDIRK Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
        RadauIIA3 & false & Error: DimensionMismatch: arguments must have the same number of rows \\
        RadauIIA5 & false & Error: DimensionMismatch: arguments must have the same number of rows \\
    \end{tabular}
    \caption{Fully-Implicit Runge-Kutta Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
        PDIRK44 & false & Error: `@threads :static` cannot be used concurrently or nested \\
    \end{tabular}
    \caption{Parallel Diagonally Implicit Runge-Kutta Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
        ROS3P     & true & \\ 
        Rodas3    & true & \\ 
        RosShamp4 & true & \\ 
        Veldd4    & true & \\ 
        Velds4    & true & \\ 
        GRK4T     & true & \\ 
        GRK4A     & true & \\ 
        Ros4LStab & true & \\ 
        Rodas4    & true & \\ 
        Rodas42   & true & \\ 
        Rodas4P   & true & \\ 
        Rodas4P2  & true & \\ 
        Rodas5    & true & \\ 
    \end{tabular}
    \caption{Rosenbrock Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktional & Fehler \\
        \hline\hline
        Rosenbrock23     & true & \\                                                                                                                          ║
        Rosenbrock32     & true & \\                                                                                                                          ║
        RosenbrockW6S4OS & true & \\                                                                                                                      ║
        ROS34PW1a        & true & \\                                                                                                                             ║
        ROS34PW1b        & true & \\                                                                                                                             ║
        ROS34PW2    & true & \\                                                                                                                              ║
        ROS34PW3         & true & \\            
    \end{tabular}
    \caption{Rosenbrock-W Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{10cm}|c|p{1cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
            ImplicitEulerExtrapolation & true & \\ 
            ImplicitDeuflhardExtrapolation & true & \\ 
            ImplicitHairerWannerExtrapolation & true & \\ 
    \end{tabular}
    \caption{Parallelized Implicit Extrapolation Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
        PDIRK44 & false & Error: `@threads :static` cannot be used concurrently or nested \\     
    \end{tabular}
    \caption{Parallelized DIRK Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
        LawsonEuler  & false & Error: ArgumeError: Caching can only be used with SplitFunction \\
        NorsettEuler & false & Error: ArgumeError: Caching can only be used with SplitFunction \\
        ETD2         & false & Error: type ODEFunction has no field f1 \\
        ETDRK2       & false & Error: ArgumeError: Caching can only be used with SplitFunction \\
        ETDRK3       & false & Error: ArgumeError: Caching can only be used with SplitFunction \\
        ETDRK4       & false & Error: ArgumeError: Caching can only be used with SplitFunction \\
        HochOst4     & false & Error: ArgumeError: Caching can only be used with SplitFunction \\
    \end{tabular}
    \caption{Exponential Runge-Kutta Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
        Exp4      & false & Error: AssertiError: Dimension mismatch \\
        EPIRK4s3A & false & Error: AssertiError: Dimension mismatch \\
        EPIRK4s3B & false & Error: AssertiError: Dimension mismatch \\
        EPIRK5P1  & false & Error: AssertiError: Dimension mismatch \\
        EPIRK5P2  & false & Error: AssertiError: Dimension mismatch \\
        EPIRK5s3  & false & Error: DimensionMismatch: tried to assign 2×1896 array to 3792×1 destination \\
        EXPRB53s3 & false & Error: AssertiError: Dimension mismatch \\
    \end{tabular}
    \caption{Exponential Propagation Iterative Runge-Kutta Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
        Exprb32 & false & Error: DimensionMismatch: array could not be broadcast to match destination \\
        Exprb43 & false & Error: DimensionMismatch: A has dimensions (3792,3792) but B has dimensions (2,1896) \\       
    \end{tabular}
    \caption{Adative Exponential Rosenbrock Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
        QNDF1 & true   & \\
        QBDF1 & true   & \\
        ABDF2 & true   & \\
        QNDF2 & true   & \\
        QBDF2 & true   & \\
        QNDF  & false  & Erros DimensionMissmatch \\
        QBDF  & false  & Erros DimensionMismatch \\
        MEBDF2& false  & Works but slow \\
        FBDF  & false  & Doesn work on gpu because scalar indexing \\
    \end{tabular}
    \caption{Mutlistep Methods}
    \label{tab:my_label}
\end{table}

\begin{table}[H]
    \centering

    \begin{tabular}{p{5cm}|c|p{5cm}}
        Name & Funktionale & Fehler \\
        \hline\hline
        SSPSDIRK2 & false & Error: MethError: Cannot `convert` an object of type Float32 to an object of type CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}║ \\        
    \end{tabular}
    \caption{Implicit Strong-Stability Preserving Runge-Kutta Methods for Hyperbolic PDEs}
    \label{tab:my_label}
\end{table}
